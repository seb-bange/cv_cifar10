# ğŸ§  Computer Vision with CIFAR-10

This project demonstrates a full deep learning workflow for image classification using the CIFAR-10 dataset. The main objective is to build, train, fine-tune, and evaluate a convolutional neural network using **Transfer Learning** with **ResNet50** (and optionally EfficientNet).

## ğŸ¯ Project Overview

- Dataset: [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)
- Framework: TensorFlow / Keras
- Approach: Transfer Learning with custom classification head
- Focus: Model training, fine-tuning, and evaluation

![Label distribution](screenshots/label_distribution.png)

---

## ğŸ“‚ Project Structure

- `Project_Computer_Vision.ipynb` â€“ Jupyter Notebook with the entire workflow
- `project_computer_vision.py` â€“ Script version of the notebook
- `Project_CV_presentation.pdf` â€“ Final project presentation (3â€“5 min pitch)

```
computer-vision-cifar10/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ Project_Computer_Vision.ipynb          # Notebook
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ project_computer_vision.py             # Python script
â”‚
â”œâ”€â”€ presentation/
â”‚   â””â”€â”€ Project_CV_presentation.pdf            # Short presentation (3-5 minutes)
â”‚
â”œâ”€â”€ screenshots/
â”‚   â”œâ”€â”€ accuracy_plot.png                      # Plot
â”‚   â”œâ”€â”€ confusion_matrix.png                   # Confusion Matrix
â”‚   â””â”€â”€ sample_predictions.png                 # Samples for wrong classififcation
â”‚
â”œâ”€â”€ README.md                                  # Project description
â”œâ”€â”€ requirements.txt                           # Requirements
```

---

## ğŸ—ï¸ Model Architecture

- **Base model:** ResNet50 (ImageNet weights, no top)
- **Custom head:**
  - GlobalAveragePooling2D
  - Dense(512) + Dropout
  - Dense(128) + Dropout
  - Softmax (10 classes)
- **Alternative (optional):** EfficientNetB0

![Custom Head](screenshots/custom_head.png)

---

## ğŸ‹ï¸â€â™‚ï¸ Training Strategy

1. **Train the custom head** with frozen base model
2. **Unfreeze base model** and fine-tune entire network
3. Use callbacks:
   - `ReduceLROnPlateau`
   - `EarlyStopping`
4. (Optional) `ImageDataGenerator` for augmentation

![Training Progress](screenshots/training_progress.png)

---

## ğŸ“Š Evaluation

- Final validation accuracy: ~72%
- Confusion matrix analysis
- Visualized wrong predictions 

### Plots:
![Accuracy curve](screenshots/accuracy.png)

![Confusion matrix](screenshots/custom_head.png)

---

## ğŸ“ Final Conclusion

- Learned how to use pretrained CNNs for image classification
- Implemented and evaluated training strategies
- Future steps:
  - Try EfficientNet or other architectures
  - Tune hyperparameters
  - Add more data/augmentation

---

## ğŸ”— Contact

ğŸ“§ [sebastian.bangemann@web.de](mailto:sebastian.bangemann@web.de)  
ğŸ”— [LinkedIn Profile](https://www.linkedin.com/in/sebastian-bangemann)

---

## ğŸ“¸ Screenshots (in `/screenshots/`)

- `accuracy.png`: Training & validation accuracy
- `conf_matrix.png`: Final evaluation
- `custom_head`: Build a custom head
- `false_predictions`: Sample of wrong predictions
- `label_distribution`: Label distribution in CIFAR10
- `training_progress`: How went the training?